{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a82b4a-4e8f-47d0-bb9d-809b43459350",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Artificial Intelligence in Entrepreneurship Education\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cba73",
   "metadata": {},
   "source": [
    "## Requirements & API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da1e65-6be0-41e6-b670-0b418904a210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.llms import OpenAIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b986df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where you input your OpenAI API Key. Don't share this with anyone and make sure you are executing in a secure environment. \n",
    "os.environ[\"OPENAI_API_KEY\"]=input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e7aaf",
   "metadata": {},
   "source": [
    "We are using the same LLM for many of these examples. However, you can alter this and replace it with your model of choice or vary the parameters if available. OpenAI GPT-3 uses a .7 temperature as a default. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15b73b-ffee-4782-bb97-899060cedfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#temperature \n",
    "llm = OpenAI(temperature=.7)\n",
    "#comment out the line above and uncomment below to use GPT 3.5 Turbo (ChatGPT) \n",
    "#llm = OpenAI(temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e145a1b-7d36-4ff2-9ed8-a2da62ee9533",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ideation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317ccd3-bf43-423f-8e00-7969f07e50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideationPrompt = PromptTemplate(\n",
    "    input_variables=[\"numberideas\"],\n",
    "    template = \"Generate {numberideas} startup ideas.\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=ideationPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e295008-4455-4236-a1a8-3f77ad280e00",
   "metadata": {},
   "source": [
    "Ideation exercises usually task students to generate new business ideas. Let's run through a few examples. First, we are going to setup a prompt chain for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384b06e-adf0-4a66-b582-2d78af9cc8b4",
   "metadata": {},
   "source": [
    "*How many ideas would you like the generative model to create?* (hint: Try less than 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6597f-e582-4130-ae65-bcf020a1aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberideas = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe41f4-fc57-4b28-9377-b941752b964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"Write a list of \"+numberideas+\" new venture ideas\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b3e24-c732-4e77-a084-12da13878644",
   "metadata": {},
   "source": [
    "**Let's see what happens to the model when we add a few additional variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86201e77-529d-425a-aa7e-cb268f26246e",
   "metadata": {},
   "source": [
    "*What industry would you like generate startup ideas for?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759198d1-4758-4dcd-bb05-711032c6d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the number of ideas you'd like to output and press enter.\n",
    "numberideas = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feaa139-b543-4f1b-a6a5-0d615cc0a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the industry you'd like the ideas to be about and press enter.\n",
    "industry = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda53a39-6837-4be6-89ab-c1e85a4183cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"Write a list of \"+numberideas+\" new venture ideas for the \"+industry+\"industry\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8365b6-c04b-423b-8832-0fd1e20beac1",
   "metadata": {},
   "source": [
    "**Now we try with a large number of variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1d7b9-3055-46bf-9f15-3aaf389a92f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Input the number of ideas. Try to pick 5 or less at a time.\n",
    "numberideas = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0783b-4504-453d-bb51-dbc0d6fc63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the industry. You can use text like \"pet taxi\" or \"commercial cleaning\"\n",
    "industry = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7339eab-52ba-4618-a082-b9488d594775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the initial capital you want to constrain the examples by. Example: $200\n",
    "initialcapital = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef9491-6f6b-41ff-bb8a-8f531a8dc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the goal for revenue generation here. Example: $1000 or \n",
    "revenuegoal = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450438c5-172d-45d2-a020-f6400283be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the characteristics of the entrepreneur. Example: \"college student\" or \"recent graduate\" \"stay at home mom\"\n",
    "entrepreneurcharacteristics = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af837bb-50ee-402b-b8ad-7a9c43d78004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the geographic location. Example: \"Ohio\" or \"Online\"\n",
    "geography = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ba93b-6713-4bed-8138-3f22b8c6e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the timeline or timeframe this would work within. Example: \"in 25 days after launching\" \"only during the weekend\"\n",
    "timeline = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9092339-d2d7-411b-8812-91ba2f7b2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This executes the command by combining the variables input above and sends it out to the GPT-3.\n",
    "print(llm(\"Write a list of \"+numberideas+\" new venture ideas a \"+entrepreneurcharacteristics+\" in \"+geography+\" could start with \"+initialcapital+\" that could generate \"+revenuegoal+\" \"+timeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb52de-6321-47d1-a73e-a3b4a4df11bf",
   "metadata": {},
   "source": [
    "An Ideation Copilot may help in brainstorming in a number of ways. First, this system may help present known solutions that an entrepreneur may not have generated. Next, it may help seed and start conversations fast. We may also be able to take another approach for ideation - by inputting the problem and generating solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610e4ec-7877-4617-a4e0-514c242bfc60",
   "metadata": {},
   "source": [
    "## Problem - Solution Ideation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b85753-b7e7-4fe7-94af-82b2c3a80fe3",
   "metadata": {},
   "source": [
    "This exercise will explore how LLMs interact in a problem-solution dyad as a way to generate possible solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df4a57-081c-4ab8-8f2b-32067557746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input a problem or a story.\n",
    "problem = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508b3d9-3701-4cee-af2a-7198487ce0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"What are 5 new venture ideas that would solve the problem in this scenario? \"+problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76395eb5-eaa5-440c-99a4-6fda1686a8c4",
   "metadata": {},
   "source": [
    "## Business Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda66cf-e855-42ed-8b21-34c962065c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the subject of the business plan. What is it about?\n",
    "subject = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cfb83-787d-4462-be55-ed48da563e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"Write the outline for a business plan about \"+subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44e33d-d978-408a-93dc-60b2593d45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This writes a specific portion of a business plan. What portion do you want it to write about?\n",
    "partofbusinessplan = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54736d1e-1b4b-422f-8448-452d4b650cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"Write a paragraph describe the \"+partofbusinessplan+\" part of a business plan about \"+subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a0427-b66e-4a2d-b73f-310526df3e11",
   "metadata": {},
   "source": [
    "Follow-up prmopt with better instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31de2af-bd0f-4379-b8fb-93050d4102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(\"Write a paragraph for the \"+partofbusinessplan+\" section of a business plan about \"+subject+\" and include financial forecasts for the first year.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5448ce5-13f7-41e1-b651-dd78fd10c709",
   "metadata": {},
   "source": [
    "### Tables and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6e999-b891-4b6f-a6af-db2de03f63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prompt asks for the data that can be used as part of a table.\n",
    "print(llm(\"Write a paragraph for the \"+partofbusinessplan+\" section of a business plan about \"+subject+\" and include a table of financial forecasts for the first year.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87f029-bee9-43fb-b0b0-57d5d52bd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prompt asks for the result to provide python code to generate the actual table or graph.\n",
    "print(llm(\"Write a paragraph for the \"+partofbusinessplan+\" section of a business plan about \"+subject+\" and include the python code to create a chart for the first year financial forecast.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8f075-b5b1-414c-98ae-82bd78af9555",
   "metadata": {},
   "source": [
    "## Cases on the Fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0aedd-5e02-48a5-a6d9-7062d320fbda",
   "metadata": {},
   "source": [
    "Most that teach an entrepreneurship class have experienced issues related to generalizability of concepts. Furthermore, there are not always simple methods to generate cases or scenarios for students to apply criticial thinking in a situated environment. Spurious generation of cases via LLMs offers a method for faculty to retain an element of localized uncertainty in the case yet still including necessary specified parameters in the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a985ab-7810-4ca2-b60f-a1acb311e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CasePrompt = PromptTemplate(\n",
    "    input_variables=[\"industry\",\"problemtopic\"],\n",
    "    template = \"Write a brief case about an entrepreneur in the {industry} industry experiencing a problem with {problemtopic}. Include 2 questions at the end of the case.\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=CasePrompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60616fdc-3523-43c2-b15e-a23736fe0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the industry this is about.\n",
    "industryinput = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the problem the entrepreneur is facing.\n",
    "problemtopicinput = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd493d-ea2d-4f09-93d1-e9de311200ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=CasePrompt)\n",
    "print(chain.predict(industry=industryinput, problemtopic=problemtopicinput))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afd066-0b28-4206-9e33-2853e1a53743",
   "metadata": {},
   "source": [
    "## Test Question Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22b7e6-f233-48c6-9bb2-e3ea17ea831d",
   "metadata": {},
   "source": [
    "Most LLMs have an easy out-of-the-box method of generating questions based on a body of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195c7d5-47a2-4b30-9a33-df44fb66db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The text you want to derive questions from.\n",
    "BaseText = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4491b-b349-4b84-a636-564bd6cc2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The instructions to the LLM to generate multiple choice questions.\n",
    "print(llm(\"Generate two multiple choice questions with 4 possible answers based on this text:\"+BaseText))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e345649-230b-402b-8dc3-e71532655f41",
   "metadata": {},
   "source": [
    "The results of these queries may be dubious - this is an area where you can vary the temperature (in the case of OpenAI) to produce output that may be better for you. As with many LLMs, its a good idea to evaluate and edit the results before using in an assessment environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b500bb-1eb5-417e-9a6e-a79d0b8080ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True or False Questions\n",
    "print(llm(\"Generate two True or False questions based on this text:\"+BaseText))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
